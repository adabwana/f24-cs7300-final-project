{"title":"Descriptive Statistics","markdown":{"yaml":{"format":{"html":{"toc":true,"toc-depth":3,"theme":"united","number-sections":false,"output-file":"neandersolve.descriptive.html"}},"code-block-background":true,"highlight-style":"atom-one"},"headingText":"Descriptive Statistics","containsRefs":false,"markdown":"\n<style></style><style>.printedClojure .sourceCode {\n  background-color: transparent;\n  border-style: none;\n}\n</style><style>.clay-limit-image-width .clay-image {max-width: 100%}\n.clay-side-by-side .sourceCode {margin: 0}\n.clay-side-by-side {margin: 1em 0}\n</style>\n<script src=\"neandersolve.descriptive_files/md-default0.js\" type=\"text/javascript\"></script><script src=\"neandersolve.descriptive_files/md-default1.js\" type=\"text/javascript\"></script>\n\n::: {.sourceClojure}\n```clojure\n(ns neandersolve.descriptive\n  (:require\n   [criterium.core :refer [quick-bench]]\n   [uncomplicate.fluokitten.core :refer [fmap!]]\n   [uncomplicate.commons.core :refer [let-release with-release]]\n   [uncomplicate.neanderthal\n    [core :refer [col copy dim dot entry entry! mrows mv!\n                  ncols nrm2 scal! sum trans vctr]]\n    [native :refer [dge dv fge fv]]\n    [math :refer [exp sqr sqrt]]\n    [vect-math :refer [abs! linear-frac! log!]]]))\n```\n:::\n\n\n\n\nStatistical analysis begins with understanding the fundamental characteristics of our data. These *descriptive measures* help us summarize and interpret large datasets through key numerical values. Our implementation prioritizes both *numerical stability* and computational efficiency.\n\n\n## Basic Statistical Measures\n\n\n### Arithmetic Mean\n\nThe *arithmetic mean* forms the foundation of many statistical computations. For a vector $x = (x_1, ..., x_n)$, the mean is defined as:\n\n$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$$\n\nWhile simple in theory, implementation requires careful consideration of *numerical stability* and efficiency.\n\n\n::: {.sourceClojure}\n```clojure\n(defn mean\n  \"Computes the arithmetic mean of a vector using pure functional operations.\n   Returns a scalar value representing the mean.\"\n  ^double [x]\n  (/ (sum x) (dim x)))\n```\n:::\n\n\nFor weighted data, we extend this concept to the *weighted mean*:\n\n$$\\bar{x}_w = \\frac{\\sum_{i=1}^n w_i x_i}{\\sum_{i=1}^n w_i}$$\n\nwhere $w_i$ represents the weight of each observation. This implementation handles edge cases by returning `NaN` for invalid inputs.\n\n\n::: {.sourceClojure}\n```clojure\n(defn weighted-mean\n  \"Computes the weighted mean of a vector given a weight vector.\n   Both vectors must have the same dimension.\n   Returns NaN if the sum of weights is zero or if vectors have different dimensions.\"\n  ^double [x weights]\n  (let [n (dim x)\n        weight-sum (sum weights)]\n    (if (and (= n (dim weights))\n             (not (zero? weight-sum)))\n      (/ (dot x weights) weight-sum)\n      Double/NaN)))\n```\n:::\n\n\n\n### Geometric Mean\n\nThe *geometric mean* provides a natural measure of *central tendency* for multiplicative processes and relative changes. For a vector $x$ of positive numbers, it is defined as:\n\n$$\\bar{x}_g = \\left(\\prod_{i=1}^n x_i\\right)^{1/n} = \\exp\\left(\\frac{1}{n}\\sum_{i=1}^n \\ln x_i\\right)$$\n\nWe compute this by transforming to *log space* to avoid numerical overflow:\n\n\n::: {.sourceClojure}\n```clojure\n(defn geometric-mean!\n  \"Computes the geometric mean of a vector using pure functional operations.\n   Returns a scalar value representing the geometric mean.\"\n  ^double [x!] ; (abs! x!) to allow negatives\n  (exp (mean (log! x!))))\n```\n:::\n\n\n\n### Harmonic Mean\n\nThe *harmonic mean* is particularly useful for averaging rates and speeds, giving more weight to smaller values. For a vector $x$, it is defined as:\n\n$$\\bar{x}_h = \\frac{n}{\\sum_{i=1}^n \\frac{1}{x_i}} = n \\left( \\sum_{i=1}^n \\frac{1}{x_i} \\right)^{-1}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn harmonic-mean!\n  \"Computes the harmonic mean of a vector.\n   Returns NaN for vectors containing zeros.\n   Modifies the input vector in place.\"\n  ^double [x!]\n  (let [n (dim x!)]\n    (if (< 0 n)\n      (/ n (sum (fmap! #(/ 1.0 %) x!)))\n      Double/NaN)))\n```\n:::\n\n\nThe arithmetic (AM), geometric (GM), and harmonic means (HM) are related through a fundamental inequality:\n\n$$ \\mathrm{AM} \\geq \\mathrm{GM} \\geq \\mathrm{HM} $$\n\nThis relationship, known as the AM-GM-HM inequality, demonstrates a consistent ordering among these measures of central tendency. The equality case occurs if and only if all elements in the sample are identical, reflecting the means' convergence for homogeneous data. See [Wikipedia](https://en.wikipedia.org/wiki/Mean#Relationship_between_AM,_GM,_and_HM).\n\n\n## Variance Computation\n\nThe *sample variance* measures the spread of data around its mean. While the theoretical formula is straightforward:\n\n$$\\sigma^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2$$\n\nA numerically stable implementation requires careful consideration to avoid *catastrophic cancellation*. We use a two-pass algorithm that first centers the data:\n\n\n::: {.sourceClojure}\n```clojure\n(defn variance!\n  \"Computes the sample variance using a numerically stable algorithm.\n   Modifies the input vector x! in place.\n   Returns NaN for empty vectors.\"\n  [x!]\n  (let [n (dim x!)]\n    (if (< 0 n)\n      (/ (sqr (nrm2 (linear-frac! 1.0 x! (- (mean x!))))) (dec n))\n      Double/NaN)))\n```\n:::\n\n\nOur implementation computes *variance* using vector operations for efficiency:\n\n- `linear-frac!` centers the data by subtracting the mean: $(x_i - x̄)$\n- `nrm2` computes the *Euclidean norm*: $\\sqrt{\\sum (x_i - x̄)^2}$\n- `sqr` gives us the sum of squared deviations: $\\sum (x_i - x̄)^2$\n- Finally, we divide by $(n-1)$ for the unbiased *sample variance*\n\nThis *vectorized approach* is mathematically equivalent to:\n$$\\sigma^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2$$\n\n\nFor cases where *preserving* the input vector is important, we provide a *non-destructive version* that works on a copy of the data:\n\n\n::: {.sourceClojure}\n```clojure\n(defn variance\n  \"Computes the sample variance using a numerically stable algorithm.\n   Preserves the input vector by working on a copy.\"\n  [x]\n  (with-release [x-copy (copy x)]\n    (variance! x-copy)))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(variance (fv 1 2 3 4 5 6 7 8 9 10))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n9.16666571749536\n\n```\n:::\n\n\n\n## Mean and Variance in a Single Pass\n\nWhile separate computations of mean and variance are straightforward, we can improve efficiency by computing both statistics in a single pass through the data. This approach reduces memory access and computational overhead, particularly important for large datasets.\n\nThe algorithm maintains running sums for both the first and second *moments* of the data. For a dataset of size $n$, we compute:\n\n$$\\mu = \\frac{1}{n}\\sum_{i=1}^n x_i$$\n$$\\sigma^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\mu)^2$$\n\nThe implementation modifies the input vector in place for efficiency, returning both statistics as a pair:\n\n\n::: {.sourceClojure}\n```clojure\n(defn mean-variance!\n  \"Computes both mean and variance in a single pass.\n   Modifies the input vector x! in place.\n   Returns [mean variance] pair, or [NaN NaN] for empty vectors.\"\n  [x!]\n  (let [n (dim x!)]\n    (if (< 0 n)\n      (let [mu (mean x!)]\n        [mu (/ (sqr (nrm2 (linear-frac! 1.0 x! (- mu)))) (dec n))]) ; or n?\n      [Double/NaN Double/NaN])))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(mean-variance! (fv 1 2 3 4 5 6 7 8 9 10))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[5.5 9.16666571749536]\n\n```\n:::\n\n\n\n## Matrix Operations\n\nStatistical computations often require working with matrices, where each column represents a variable and each row an observation. We begin with computing means across *matrix columns*.\n\nThe *matrix mean* operation computes the *arithmetic mean* for each column, effectively reducing a matrix to a vector of column means:\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-mean\n  \"Computes column means of a matrix.\n   Returns a vector where each element is the mean of the corresponding column.\"\n  ([a ones res!]\n   (if (< 0 (mrows a))\n     (mv! (/ 1.0 (mrows a)) (trans a) ones 0.0 res!)\n     (entry! res! Double/NaN)))\n  ([a ones]\n   (let-release [res (vctr a (ncols a))]\n                (matrix-mean a ones res)))\n  ([a]\n   (with-release [ones (entry! (vctr a (mrows a)) 1.0)]\n     (matrix-mean a ones))))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(matrix-mean (fge 3 2 [4 2 3 4 5 6]))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n#RealBlockVector[float, n:2, stride:1]\n[   3.00    5.00 ]\n\n\n```\n:::\n\n\nThe matrix variance computation extends our vector operations to handle multiple variables simultaneously. For each column $j$ in matrix $A$, we compute:\n\n$$\\sigma^2_j = \\frac{1}{n-1}\\sum_{i=1}^n (a_{ij} - \\mu_j)^2$$\n\nWe provide both in-place and copying versions to accommodate different usage patterns:\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-variance!\n  \"Computes column variances of a matrix in-place.\n   Modifies the input matrix a! during computation.\"\n  [a!]\n  (let [n (ncols a!)\n        result (vctr a! n)]\n    (loop [j 0]\n      (when (< j n)\n        (entry! result j (variance (col a! j)))\n        (recur (inc j))))\n    result))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-variance\n  \"Computes column variances of a matrix.\n   Preserves the input matrix by working on a copy.\"\n  [a]\n  (with-release [a-copy (copy a)]\n    (matrix-variance! a-copy)))\n```\n:::\n\n\n\n## Standard Error\n\nThe standard error of the mean quantifies the uncertainty in our estimate of the population mean. For a sample of size $n$, it is defined as:\n\n$$SE = \\frac{\\sigma}{\\sqrt{n}}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn standard-error\n  \"Computes the standard error of the mean.\"\n  [x]\n  (let [n (dim x)]\n    (sqrt (/ (variance x) n))))\n```\n:::\n\n\nIt is important to distinguish between the standard error of the mean and the standard deviation. While both are frequently used to summarize data, they serve distinct statistical purposes:\n\n- The standard deviation characterizes the variability of individual observations within the sample\n- The standard error quantifies the precision of the sample mean as an estimator of the population mean\n\nAs sample size increases, the standard error decreases (approaching zero), reflecting improved estimation precision, while the standard deviation converges to the true population parameter. This relationship emerges from the central limit theorem and forms the basis for statistical inference.\n\nThe standard deviation, $\\sigma$, is the sample standard deviation calculated as the square root of the variance:\n\n$$\\sigma = \\sqrt{\\mathrm{Var}(X)}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn sd [x]\n  (sqrt (variance x)))\n```\n:::\n\n\n\n## Covariance Calculations\n\n*Covariance* measures the joint variability between two variables. For vectors $x$ and $y$, the *sample covariance* is defined as:\n\n$$cov(x,y) = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})$$\n\nThe implementation first centers both vectors and then computes their *dot product*:\n\n\n::: {.sourceClojure}\n```clojure\n(defn covariance!\n  \"Computes covariance between two vectors in-place.\n   Modifies both input vectors during computation.\"\n  [x! y!]\n  (let [n (dim x!)\n        x-mean (mean x!)\n        y-mean (mean y!)\n        x-centered (linear-frac! 1.0 x! (- x-mean))\n        y-centered (linear-frac! 1.0 y! (- y-mean))]\n    (/ (dot x-centered y-centered) (dec n))))\n```\n:::\n\n\nFor applications requiring preservation of input data, we provide a non-destructive version:\n\n\n::: {.sourceClojure}\n```clojure\n(defn covariance\n  \"Computes covariance between two vectors.\"\n  [x y]\n  (with-release [x-copy (copy x)\n                 y-copy (copy y)]\n    (covariance! x-copy y-copy)))\n```\n:::\n\n\nThe *covariance matrix* extends this concept to multiple variables. For a data matrix $X$ with $n$ observations and $p$ variables, the covariance matrix $\\Sigma$ has elements:\n\n$$\\Sigma_{ij} = \\frac{1}{n-1}\\sum_{k=1}^n (x_{ki} - \\bar{x}_i)(x_{kj} - \\bar{x}_j)$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-covariance\n  \"Computes the covariance matrix for a data matrix X.\n   Each row represents an observation, each column a variable.\"\n  [X]\n  (let [n (mrows X)\n        p (ncols X)\n        result (dge p p)\n        X-mean (copy X)]\n    ;; Center the data\n    (loop [j 0]\n      (when (< j p)\n        (let [col-j (col X-mean j)\n              col-mean (mean col-j)]\n          (linear-frac! 1.0 col-j (- col-mean))\n          (recur (inc j)))))\n    ;; Compute covariances\n    (loop [i 0]\n      (when (< i p)\n        (loop [j i]\n          (when (< j p)\n            (let [cov (/ (dot (col X-mean i) (col X-mean j))\n                         (dec n))]\n              (entry! result i j cov)\n              (when (not= i j)\n                (entry! result j i cov)))\n            (recur (inc j))))\n        (recur (inc i))))\n    result))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(matrix-covariance (dge 3 2 [4 2 3 4 50 6]))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n#RealGEMatrix[double, mxn:2x2, layout:column]\n   ▥       ↓       ↓       ┓    \n   →       1.00  -23.00         \n   →     -23.00  676.00         \n   ┗                       ┛    \n\n\n```\n:::\n\n\n\n## Correlation Analysis\n\n*Correlation* normalizes *covariance* to produce a standardized measure of *linear association* between variables. The *Pearson correlation coefficient* is defined as:\n\n$$\\rho_{xy} = \\frac{cov(x,y)}{\\sigma_x\\sigma_y}$$\n\nOur implementation centers the data and normalizes by the vector *norms*:\n\n\n::: {.sourceClojure}\n```clojure\n(defn correlation!\n  \"Computes correlation between two vectors in-place.\n   Modifies both input vectors during computation.\"\n  [x! y!]\n  (let [x-mean (mean x!)\n        y-mean (mean y!)\n        x-centered (linear-frac! 1.0 x! (- x-mean))\n        y-centered (linear-frac! 1.0 y! (- y-mean))\n        x-norm (nrm2 x-centered)\n        y-norm (nrm2 y-centered)]\n    (if (and (not (zero? x-norm))\n             (not (zero? y-norm)))\n      (/ (dot x-centered y-centered)\n         (* x-norm y-norm))\n      0.0)))\n```\n:::\n\n\nAs with covariance, we provide a non-destructive version:\n\n\n::: {.sourceClojure}\n```clojure\n(defn correlation\n  \"Computes correlation between two vectors.\"\n  [x y]\n  (with-release [x-copy (copy x)\n                 y-copy (copy y)]\n    (correlation! x-copy y-copy)))\n```\n:::\n\n\nThe *correlation matrix* contains all pairwise correlations between variables. For a data matrix $X$, each element is:\n\n$$R_{ij} = \\frac{\\sum_{k=1}^n (x_{ki} - \\bar{x}_i)(x_{kj} - \\bar{x}_j)}{\\sqrt{\\sum_{k=1}^n (x_{ki} - \\bar{x}_i)^2\\sum_{k=1}^n (x_{kj} - \\bar{x}_j)^2}}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-correlation\n  \"Computes the correlation matrix for a data matrix X.\n   Each row represents an observation, each column a variable.\"\n  [X]\n  (let [n (mrows X)\n        p (ncols X)\n        result (dge p p)\n        X-mean (copy X)]\n    ;; Center and normalize the data\n    (loop [j 0]\n      (when (< j p)\n        (let [col-j (col X-mean j)\n              col-mean (mean col-j)]\n          ;; Center the column\n          (linear-frac! 1.0 col-j (- col-mean))\n          ;; Scale to unit norm\n          (let [norm (nrm2 col-j)]\n            (when (> norm 0.0)\n              (scal! (/ 1.0 norm) col-j)))\n          (recur (inc j)))))\n    ;; Compute correlations\n    (loop [i 0]\n      (when (< i p)\n        (loop [j i]\n          (when (< j p)\n            (let [corr (dot (col X-mean i) (col X-mean j))]\n              (entry! result i j corr)\n              (when (not= i j)\n                (entry! result j i corr)))\n            (recur (inc j))))\n        (recur (inc i))))\n    result))\n```\n:::\n\n\n\n## Data Standardization\n\n*Standardization* transforms variables to have zero mean and unit variance. For a vector $x$, the *z-score transformation* is:\n\n$$z_i = \\frac{x_i - \\bar{x}}{\\sigma_x}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn z-score\n  \"Standardizes a vector to have mean 0 and standard deviation 1.\"\n  [x]\n  (let [[mu sigma] (mean-variance! (copy x))\n        result (copy x)]\n    (linear-frac! 1.0 result (- mu))\n    (when (not (zero? sigma))\n      (scal! (/ 1.0 (sqrt sigma)) result))\n    result))\n```\n:::\n\n\nFor matrix data, we provide functions to center and standardize all columns:\n\n\n::: {.sourceClojure}\n```clojure\n(defn center!\n  \"Centers a matrix by subtracting the mean of each column.\"\n  [a!]\n  (loop [j 0]\n    (when (< j (ncols a!))\n      (let [col-j (col a! j)]\n        (linear-frac! 1.0 col-j (- (mean col-j)))\n        (recur (inc j)))))\n  a!)\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn standardize!\n  \"Standardizes a matrix by centering and scaling to unit variance.\n   Modifies the input matrix in place.\n   Returns the modified matrix.\"\n  [a!]\n  (let [n (mrows a!)\n        p (ncols a!)]\n    ;; First center the data\n    (center! a!)\n    ;; Then scale to unit variance\n    (loop [j 0]\n      (when (< j p)\n        (let [col-j (col a! j)\n              ss (dot col-j col-j)  ; sum of squares of centered data\n              std-dev (sqrt (/ ss (dec n)))]\n          (when (> std-dev 0.0)\n            (scal! (/ 1.0 std-dev) col-j))\n          (recur (inc j)))))\n    a!))\n```\n:::\n\n\n\n## Data Normalization\n\nIn data analysis and machine learning, the scale of features can significantly impact algorithm performance. When different features have vastly different ranges, they can dominate or diminish the influence of other features inappropriately. *Normalization* addresses this by transforming features to comparable scales.\n\n\n### Min-Max Scaling\n\nThe simplest form of *normalization* maps values to the interval $[0,1]$. For a feature vector $x$, the transformation is:\n\n$$x_{normalized} = \\frac{x - min(x)}{max(x) - min(x)}$$\n\nThis *linear scaling* preserves zero differences and the relative ordering of values while bounding them within $[0,1]$.\nWhen applied to matrices, the transformation is performed column-wise, treating each feature independently.\n\n\n::: {.sourceClojure}\n```clojure\n(defn min-max!\n  \"Normalizes vectors or matrices to the range [0, 1] in-place.\n   For matrices, normalizes each column independently.\n   Modifies the input in place.\n   Returns the modified input.\n   Returns columns unchanged if max equals min.\"\n  [x!]\n  (if (vector? x!)\n    ; Vector case\n    (let [n (dim x!)\n          [min-x max-x] (loop [i 1\n                               min-val (entry x! 0)\n                               max-val (entry x! 0)]\n                         (if (< i n)\n                           (let [val (entry x! i)]\n                             (recur (inc i)\n                                    (min min-val val)\n                                    (max max-val val)))\n                           [min-val max-val]))\n          range (- max-x min-x)]\n      (if (zero? range)\n        x!  ; Return unchanged if all values are the same\n        (linear-frac! (/ 1.0 range) x! (/ (- min-x) range))))\n    ; Matrix case - normalize each column\n    (let [m (mrows x!)\n          n (ncols x!)]\n      (dotimes [j n]\n        (let [col-j (col x! j)\n              [min-x max-x] (loop [i 1\n                                   min-val (entry col-j 0)\n                                   max-val (entry col-j 0)]\n                             (if (< i m)\n                               (let [val (entry col-j i)]\n                                 (recur (inc i)\n                                        (min min-val val)\n                                        (max max-val val)))\n                               [min-val max-val]))\n              range (- max-x min-x)]\n          (when-not (zero? range)\n            (linear-frac! (/ 1.0 range) col-j (/ (- min-x) range)))))\n      x!)))\n```\n:::\n\n\n\n### Feature Scaling\n\nFor algorithms sensitive to the sign of inputs or requiring symmetric ranges, scaling to [-1,1] is often more appropriate. The transformation extends min-max scaling:\n\n$$x_{normalized} = 2 \\cdot \\frac{x - min(x)}{max(x) - min(x)} - 1$$\n\nThis centers the data around zero while maintaining relative distances between points.\nFor matrices, each column is scaled independently to preserve feature-specific ranges.\n\n\n::: {.sourceClojure}\n```clojure\n(defn feature-scale!\n  \"Normalizes vectors or matrices to the range [-1, 1] in-place.\n   For matrices, normalizes each column independently.\n   Modifies the input in place.\n   Returns the modified input.\n   Returns columns unchanged if max equals min.\"\n  [x!]\n  (if (vector? x!)\n    ; Vector case\n    (let [n (dim x!)\n          [min-x max-x] (loop [i 1\n                               min-val (entry x! 0)\n                               max-val (entry x! 0)]\n                         (if (< i n)\n                           (let [val (entry x! i)]\n                             (recur (inc i)\n                                    (min min-val val)\n                                    (max max-val val)))\n                           [min-val max-val]))\n          range (- max-x min-x)]\n      (if (zero? range)\n        x!  ; Return unchanged if all values are the same\n        (linear-frac! (/ 2.0 range) x! (- (/ (+ min-x max-x) range)))))\n    ; Matrix case - normalize each column\n    (let [m (mrows x!)\n          n (ncols x!)]\n      (dotimes [j n]\n        (let [col-j (col x! j)\n              [min-x max-x] (loop [i 1\n                                   min-val (entry col-j 0)\n                                   max-val (entry col-j 0)]\n                             (if (< i m)\n                               (let [val (entry col-j i)]\n                                 (recur (inc i)\n                                        (min min-val val)\n                                        (max max-val val)))\n                               [min-val max-val]))\n              range (- max-x min-x)]\n          (when-not (zero? range)\n            (linear-frac! (/ 2.0 range) col-j (- (/ (+ min-x max-x) range))))))\n      x!)))\n```\n:::\n\n\n\n## Conclusion\n\nDescriptive statistics provide the foundation for understanding and preparing data for advanced analysis. The implementations in this chapter demonstrate how to efficiently compute and transform data while adhering to numerical computing best practices.\n\nThese tools provide essential data preprocessing capabilities for statistical analysis and machine learning applications. While what we have implemented is not exhaustive, it provides a foundation for more complex statistical computations. Next steps would be to implement robust statistics and more advanced data transformations.\n\n\n### Robust Statistics\n\nWhile *mean* and *variance* are fundamental statistical measures, they can be sensitive to *outliers* and extreme values. *Robust statistics* provide alternative measures that are less affected by anomalous data points.\n\n\n#### Median and Quantiles\n\nThe *median* is the middle value when data is ordered. For an odd number of observations, it is the middle value; for an even number, it is the average of the two middle values. Unlike the mean, the median is not influenced by extreme values.\n\nMore generally, *quantiles* divide ordered data into equal-sized groups. The *p-th quantile* is the value below which a proportion $p$ of the observations fall. Common quantiles include:\n\n- *Quartiles* (dividing data into four parts)\n- *Deciles* (ten parts)\n- *Percentiles* (hundred parts)\n\n\n#### Robust Scale Estimates\n\nThe *Median Absolute Deviation* (MAD) is a robust measure of variability:\n\n$$MAD = median(|x_i - median(x)|)$$\n\nThe MAD is particularly useful when data contains outliers that would distort the standard deviation.\n\n\n## Implementation Notes\n\n\n### Performance Considerations\n\nFor large datasets, consider:\n\n1. Using *in-place operations* when input preservation isn't required\n2. *Batching operations* to minimize memory allocation\n3. Taking advantage of *parallel processing* capabilities where available\n\nThe implementation uses *BLAS* (Basic Linear Algebra Subprograms) operations where possible for optimal performance on numerical computations.\n\n\n```{=html}\n<div style=\"background-color:grey;height:2px;width:100%;\"></div>\n```\n\n\n\n```{=html}\n<div></div>\n```\n","srcMarkdownNoYaml":"\n<style></style><style>.printedClojure .sourceCode {\n  background-color: transparent;\n  border-style: none;\n}\n</style><style>.clay-limit-image-width .clay-image {max-width: 100%}\n.clay-side-by-side .sourceCode {margin: 0}\n.clay-side-by-side {margin: 1em 0}\n</style>\n<script src=\"neandersolve.descriptive_files/md-default0.js\" type=\"text/javascript\"></script><script src=\"neandersolve.descriptive_files/md-default1.js\" type=\"text/javascript\"></script>\n\n::: {.sourceClojure}\n```clojure\n(ns neandersolve.descriptive\n  (:require\n   [criterium.core :refer [quick-bench]]\n   [uncomplicate.fluokitten.core :refer [fmap!]]\n   [uncomplicate.commons.core :refer [let-release with-release]]\n   [uncomplicate.neanderthal\n    [core :refer [col copy dim dot entry entry! mrows mv!\n                  ncols nrm2 scal! sum trans vctr]]\n    [native :refer [dge dv fge fv]]\n    [math :refer [exp sqr sqrt]]\n    [vect-math :refer [abs! linear-frac! log!]]]))\n```\n:::\n\n\n\n# Descriptive Statistics\n\nStatistical analysis begins with understanding the fundamental characteristics of our data. These *descriptive measures* help us summarize and interpret large datasets through key numerical values. Our implementation prioritizes both *numerical stability* and computational efficiency.\n\n\n## Basic Statistical Measures\n\n\n### Arithmetic Mean\n\nThe *arithmetic mean* forms the foundation of many statistical computations. For a vector $x = (x_1, ..., x_n)$, the mean is defined as:\n\n$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$$\n\nWhile simple in theory, implementation requires careful consideration of *numerical stability* and efficiency.\n\n\n::: {.sourceClojure}\n```clojure\n(defn mean\n  \"Computes the arithmetic mean of a vector using pure functional operations.\n   Returns a scalar value representing the mean.\"\n  ^double [x]\n  (/ (sum x) (dim x)))\n```\n:::\n\n\nFor weighted data, we extend this concept to the *weighted mean*:\n\n$$\\bar{x}_w = \\frac{\\sum_{i=1}^n w_i x_i}{\\sum_{i=1}^n w_i}$$\n\nwhere $w_i$ represents the weight of each observation. This implementation handles edge cases by returning `NaN` for invalid inputs.\n\n\n::: {.sourceClojure}\n```clojure\n(defn weighted-mean\n  \"Computes the weighted mean of a vector given a weight vector.\n   Both vectors must have the same dimension.\n   Returns NaN if the sum of weights is zero or if vectors have different dimensions.\"\n  ^double [x weights]\n  (let [n (dim x)\n        weight-sum (sum weights)]\n    (if (and (= n (dim weights))\n             (not (zero? weight-sum)))\n      (/ (dot x weights) weight-sum)\n      Double/NaN)))\n```\n:::\n\n\n\n### Geometric Mean\n\nThe *geometric mean* provides a natural measure of *central tendency* for multiplicative processes and relative changes. For a vector $x$ of positive numbers, it is defined as:\n\n$$\\bar{x}_g = \\left(\\prod_{i=1}^n x_i\\right)^{1/n} = \\exp\\left(\\frac{1}{n}\\sum_{i=1}^n \\ln x_i\\right)$$\n\nWe compute this by transforming to *log space* to avoid numerical overflow:\n\n\n::: {.sourceClojure}\n```clojure\n(defn geometric-mean!\n  \"Computes the geometric mean of a vector using pure functional operations.\n   Returns a scalar value representing the geometric mean.\"\n  ^double [x!] ; (abs! x!) to allow negatives\n  (exp (mean (log! x!))))\n```\n:::\n\n\n\n### Harmonic Mean\n\nThe *harmonic mean* is particularly useful for averaging rates and speeds, giving more weight to smaller values. For a vector $x$, it is defined as:\n\n$$\\bar{x}_h = \\frac{n}{\\sum_{i=1}^n \\frac{1}{x_i}} = n \\left( \\sum_{i=1}^n \\frac{1}{x_i} \\right)^{-1}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn harmonic-mean!\n  \"Computes the harmonic mean of a vector.\n   Returns NaN for vectors containing zeros.\n   Modifies the input vector in place.\"\n  ^double [x!]\n  (let [n (dim x!)]\n    (if (< 0 n)\n      (/ n (sum (fmap! #(/ 1.0 %) x!)))\n      Double/NaN)))\n```\n:::\n\n\nThe arithmetic (AM), geometric (GM), and harmonic means (HM) are related through a fundamental inequality:\n\n$$ \\mathrm{AM} \\geq \\mathrm{GM} \\geq \\mathrm{HM} $$\n\nThis relationship, known as the AM-GM-HM inequality, demonstrates a consistent ordering among these measures of central tendency. The equality case occurs if and only if all elements in the sample are identical, reflecting the means' convergence for homogeneous data. See [Wikipedia](https://en.wikipedia.org/wiki/Mean#Relationship_between_AM,_GM,_and_HM).\n\n\n## Variance Computation\n\nThe *sample variance* measures the spread of data around its mean. While the theoretical formula is straightforward:\n\n$$\\sigma^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2$$\n\nA numerically stable implementation requires careful consideration to avoid *catastrophic cancellation*. We use a two-pass algorithm that first centers the data:\n\n\n::: {.sourceClojure}\n```clojure\n(defn variance!\n  \"Computes the sample variance using a numerically stable algorithm.\n   Modifies the input vector x! in place.\n   Returns NaN for empty vectors.\"\n  [x!]\n  (let [n (dim x!)]\n    (if (< 0 n)\n      (/ (sqr (nrm2 (linear-frac! 1.0 x! (- (mean x!))))) (dec n))\n      Double/NaN)))\n```\n:::\n\n\nOur implementation computes *variance* using vector operations for efficiency:\n\n- `linear-frac!` centers the data by subtracting the mean: $(x_i - x̄)$\n- `nrm2` computes the *Euclidean norm*: $\\sqrt{\\sum (x_i - x̄)^2}$\n- `sqr` gives us the sum of squared deviations: $\\sum (x_i - x̄)^2$\n- Finally, we divide by $(n-1)$ for the unbiased *sample variance*\n\nThis *vectorized approach* is mathematically equivalent to:\n$$\\sigma^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})^2$$\n\n\nFor cases where *preserving* the input vector is important, we provide a *non-destructive version* that works on a copy of the data:\n\n\n::: {.sourceClojure}\n```clojure\n(defn variance\n  \"Computes the sample variance using a numerically stable algorithm.\n   Preserves the input vector by working on a copy.\"\n  [x]\n  (with-release [x-copy (copy x)]\n    (variance! x-copy)))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(variance (fv 1 2 3 4 5 6 7 8 9 10))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n9.16666571749536\n\n```\n:::\n\n\n\n## Mean and Variance in a Single Pass\n\nWhile separate computations of mean and variance are straightforward, we can improve efficiency by computing both statistics in a single pass through the data. This approach reduces memory access and computational overhead, particularly important for large datasets.\n\nThe algorithm maintains running sums for both the first and second *moments* of the data. For a dataset of size $n$, we compute:\n\n$$\\mu = \\frac{1}{n}\\sum_{i=1}^n x_i$$\n$$\\sigma^2 = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\mu)^2$$\n\nThe implementation modifies the input vector in place for efficiency, returning both statistics as a pair:\n\n\n::: {.sourceClojure}\n```clojure\n(defn mean-variance!\n  \"Computes both mean and variance in a single pass.\n   Modifies the input vector x! in place.\n   Returns [mean variance] pair, or [NaN NaN] for empty vectors.\"\n  [x!]\n  (let [n (dim x!)]\n    (if (< 0 n)\n      (let [mu (mean x!)]\n        [mu (/ (sqr (nrm2 (linear-frac! 1.0 x! (- mu)))) (dec n))]) ; or n?\n      [Double/NaN Double/NaN])))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(mean-variance! (fv 1 2 3 4 5 6 7 8 9 10))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[5.5 9.16666571749536]\n\n```\n:::\n\n\n\n## Matrix Operations\n\nStatistical computations often require working with matrices, where each column represents a variable and each row an observation. We begin with computing means across *matrix columns*.\n\nThe *matrix mean* operation computes the *arithmetic mean* for each column, effectively reducing a matrix to a vector of column means:\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-mean\n  \"Computes column means of a matrix.\n   Returns a vector where each element is the mean of the corresponding column.\"\n  ([a ones res!]\n   (if (< 0 (mrows a))\n     (mv! (/ 1.0 (mrows a)) (trans a) ones 0.0 res!)\n     (entry! res! Double/NaN)))\n  ([a ones]\n   (let-release [res (vctr a (ncols a))]\n                (matrix-mean a ones res)))\n  ([a]\n   (with-release [ones (entry! (vctr a (mrows a)) 1.0)]\n     (matrix-mean a ones))))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(matrix-mean (fge 3 2 [4 2 3 4 5 6]))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n#RealBlockVector[float, n:2, stride:1]\n[   3.00    5.00 ]\n\n\n```\n:::\n\n\nThe matrix variance computation extends our vector operations to handle multiple variables simultaneously. For each column $j$ in matrix $A$, we compute:\n\n$$\\sigma^2_j = \\frac{1}{n-1}\\sum_{i=1}^n (a_{ij} - \\mu_j)^2$$\n\nWe provide both in-place and copying versions to accommodate different usage patterns:\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-variance!\n  \"Computes column variances of a matrix in-place.\n   Modifies the input matrix a! during computation.\"\n  [a!]\n  (let [n (ncols a!)\n        result (vctr a! n)]\n    (loop [j 0]\n      (when (< j n)\n        (entry! result j (variance (col a! j)))\n        (recur (inc j))))\n    result))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-variance\n  \"Computes column variances of a matrix.\n   Preserves the input matrix by working on a copy.\"\n  [a]\n  (with-release [a-copy (copy a)]\n    (matrix-variance! a-copy)))\n```\n:::\n\n\n\n## Standard Error\n\nThe standard error of the mean quantifies the uncertainty in our estimate of the population mean. For a sample of size $n$, it is defined as:\n\n$$SE = \\frac{\\sigma}{\\sqrt{n}}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn standard-error\n  \"Computes the standard error of the mean.\"\n  [x]\n  (let [n (dim x)]\n    (sqrt (/ (variance x) n))))\n```\n:::\n\n\nIt is important to distinguish between the standard error of the mean and the standard deviation. While both are frequently used to summarize data, they serve distinct statistical purposes:\n\n- The standard deviation characterizes the variability of individual observations within the sample\n- The standard error quantifies the precision of the sample mean as an estimator of the population mean\n\nAs sample size increases, the standard error decreases (approaching zero), reflecting improved estimation precision, while the standard deviation converges to the true population parameter. This relationship emerges from the central limit theorem and forms the basis for statistical inference.\n\nThe standard deviation, $\\sigma$, is the sample standard deviation calculated as the square root of the variance:\n\n$$\\sigma = \\sqrt{\\mathrm{Var}(X)}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn sd [x]\n  (sqrt (variance x)))\n```\n:::\n\n\n\n## Covariance Calculations\n\n*Covariance* measures the joint variability between two variables. For vectors $x$ and $y$, the *sample covariance* is defined as:\n\n$$cov(x,y) = \\frac{1}{n-1}\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})$$\n\nThe implementation first centers both vectors and then computes their *dot product*:\n\n\n::: {.sourceClojure}\n```clojure\n(defn covariance!\n  \"Computes covariance between two vectors in-place.\n   Modifies both input vectors during computation.\"\n  [x! y!]\n  (let [n (dim x!)\n        x-mean (mean x!)\n        y-mean (mean y!)\n        x-centered (linear-frac! 1.0 x! (- x-mean))\n        y-centered (linear-frac! 1.0 y! (- y-mean))]\n    (/ (dot x-centered y-centered) (dec n))))\n```\n:::\n\n\nFor applications requiring preservation of input data, we provide a non-destructive version:\n\n\n::: {.sourceClojure}\n```clojure\n(defn covariance\n  \"Computes covariance between two vectors.\"\n  [x y]\n  (with-release [x-copy (copy x)\n                 y-copy (copy y)]\n    (covariance! x-copy y-copy)))\n```\n:::\n\n\nThe *covariance matrix* extends this concept to multiple variables. For a data matrix $X$ with $n$ observations and $p$ variables, the covariance matrix $\\Sigma$ has elements:\n\n$$\\Sigma_{ij} = \\frac{1}{n-1}\\sum_{k=1}^n (x_{ki} - \\bar{x}_i)(x_{kj} - \\bar{x}_j)$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-covariance\n  \"Computes the covariance matrix for a data matrix X.\n   Each row represents an observation, each column a variable.\"\n  [X]\n  (let [n (mrows X)\n        p (ncols X)\n        result (dge p p)\n        X-mean (copy X)]\n    ;; Center the data\n    (loop [j 0]\n      (when (< j p)\n        (let [col-j (col X-mean j)\n              col-mean (mean col-j)]\n          (linear-frac! 1.0 col-j (- col-mean))\n          (recur (inc j)))))\n    ;; Compute covariances\n    (loop [i 0]\n      (when (< i p)\n        (loop [j i]\n          (when (< j p)\n            (let [cov (/ (dot (col X-mean i) (col X-mean j))\n                         (dec n))]\n              (entry! result i j cov)\n              (when (not= i j)\n                (entry! result j i cov)))\n            (recur (inc j))))\n        (recur (inc i))))\n    result))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(matrix-covariance (dge 3 2 [4 2 3 4 50 6]))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n#RealGEMatrix[double, mxn:2x2, layout:column]\n   ▥       ↓       ↓       ┓    \n   →       1.00  -23.00         \n   →     -23.00  676.00         \n   ┗                       ┛    \n\n\n```\n:::\n\n\n\n## Correlation Analysis\n\n*Correlation* normalizes *covariance* to produce a standardized measure of *linear association* between variables. The *Pearson correlation coefficient* is defined as:\n\n$$\\rho_{xy} = \\frac{cov(x,y)}{\\sigma_x\\sigma_y}$$\n\nOur implementation centers the data and normalizes by the vector *norms*:\n\n\n::: {.sourceClojure}\n```clojure\n(defn correlation!\n  \"Computes correlation between two vectors in-place.\n   Modifies both input vectors during computation.\"\n  [x! y!]\n  (let [x-mean (mean x!)\n        y-mean (mean y!)\n        x-centered (linear-frac! 1.0 x! (- x-mean))\n        y-centered (linear-frac! 1.0 y! (- y-mean))\n        x-norm (nrm2 x-centered)\n        y-norm (nrm2 y-centered)]\n    (if (and (not (zero? x-norm))\n             (not (zero? y-norm)))\n      (/ (dot x-centered y-centered)\n         (* x-norm y-norm))\n      0.0)))\n```\n:::\n\n\nAs with covariance, we provide a non-destructive version:\n\n\n::: {.sourceClojure}\n```clojure\n(defn correlation\n  \"Computes correlation between two vectors.\"\n  [x y]\n  (with-release [x-copy (copy x)\n                 y-copy (copy y)]\n    (correlation! x-copy y-copy)))\n```\n:::\n\n\nThe *correlation matrix* contains all pairwise correlations between variables. For a data matrix $X$, each element is:\n\n$$R_{ij} = \\frac{\\sum_{k=1}^n (x_{ki} - \\bar{x}_i)(x_{kj} - \\bar{x}_j)}{\\sqrt{\\sum_{k=1}^n (x_{ki} - \\bar{x}_i)^2\\sum_{k=1}^n (x_{kj} - \\bar{x}_j)^2}}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn matrix-correlation\n  \"Computes the correlation matrix for a data matrix X.\n   Each row represents an observation, each column a variable.\"\n  [X]\n  (let [n (mrows X)\n        p (ncols X)\n        result (dge p p)\n        X-mean (copy X)]\n    ;; Center and normalize the data\n    (loop [j 0]\n      (when (< j p)\n        (let [col-j (col X-mean j)\n              col-mean (mean col-j)]\n          ;; Center the column\n          (linear-frac! 1.0 col-j (- col-mean))\n          ;; Scale to unit norm\n          (let [norm (nrm2 col-j)]\n            (when (> norm 0.0)\n              (scal! (/ 1.0 norm) col-j)))\n          (recur (inc j)))))\n    ;; Compute correlations\n    (loop [i 0]\n      (when (< i p)\n        (loop [j i]\n          (when (< j p)\n            (let [corr (dot (col X-mean i) (col X-mean j))]\n              (entry! result i j corr)\n              (when (not= i j)\n                (entry! result j i corr)))\n            (recur (inc j))))\n        (recur (inc i))))\n    result))\n```\n:::\n\n\n\n## Data Standardization\n\n*Standardization* transforms variables to have zero mean and unit variance. For a vector $x$, the *z-score transformation* is:\n\n$$z_i = \\frac{x_i - \\bar{x}}{\\sigma_x}$$\n\n\n::: {.sourceClojure}\n```clojure\n(defn z-score\n  \"Standardizes a vector to have mean 0 and standard deviation 1.\"\n  [x]\n  (let [[mu sigma] (mean-variance! (copy x))\n        result (copy x)]\n    (linear-frac! 1.0 result (- mu))\n    (when (not (zero? sigma))\n      (scal! (/ 1.0 (sqrt sigma)) result))\n    result))\n```\n:::\n\n\nFor matrix data, we provide functions to center and standardize all columns:\n\n\n::: {.sourceClojure}\n```clojure\n(defn center!\n  \"Centers a matrix by subtracting the mean of each column.\"\n  [a!]\n  (loop [j 0]\n    (when (< j (ncols a!))\n      (let [col-j (col a! j)]\n        (linear-frac! 1.0 col-j (- (mean col-j)))\n        (recur (inc j)))))\n  a!)\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn standardize!\n  \"Standardizes a matrix by centering and scaling to unit variance.\n   Modifies the input matrix in place.\n   Returns the modified matrix.\"\n  [a!]\n  (let [n (mrows a!)\n        p (ncols a!)]\n    ;; First center the data\n    (center! a!)\n    ;; Then scale to unit variance\n    (loop [j 0]\n      (when (< j p)\n        (let [col-j (col a! j)\n              ss (dot col-j col-j)  ; sum of squares of centered data\n              std-dev (sqrt (/ ss (dec n)))]\n          (when (> std-dev 0.0)\n            (scal! (/ 1.0 std-dev) col-j))\n          (recur (inc j)))))\n    a!))\n```\n:::\n\n\n\n## Data Normalization\n\nIn data analysis and machine learning, the scale of features can significantly impact algorithm performance. When different features have vastly different ranges, they can dominate or diminish the influence of other features inappropriately. *Normalization* addresses this by transforming features to comparable scales.\n\n\n### Min-Max Scaling\n\nThe simplest form of *normalization* maps values to the interval $[0,1]$. For a feature vector $x$, the transformation is:\n\n$$x_{normalized} = \\frac{x - min(x)}{max(x) - min(x)}$$\n\nThis *linear scaling* preserves zero differences and the relative ordering of values while bounding them within $[0,1]$.\nWhen applied to matrices, the transformation is performed column-wise, treating each feature independently.\n\n\n::: {.sourceClojure}\n```clojure\n(defn min-max!\n  \"Normalizes vectors or matrices to the range [0, 1] in-place.\n   For matrices, normalizes each column independently.\n   Modifies the input in place.\n   Returns the modified input.\n   Returns columns unchanged if max equals min.\"\n  [x!]\n  (if (vector? x!)\n    ; Vector case\n    (let [n (dim x!)\n          [min-x max-x] (loop [i 1\n                               min-val (entry x! 0)\n                               max-val (entry x! 0)]\n                         (if (< i n)\n                           (let [val (entry x! i)]\n                             (recur (inc i)\n                                    (min min-val val)\n                                    (max max-val val)))\n                           [min-val max-val]))\n          range (- max-x min-x)]\n      (if (zero? range)\n        x!  ; Return unchanged if all values are the same\n        (linear-frac! (/ 1.0 range) x! (/ (- min-x) range))))\n    ; Matrix case - normalize each column\n    (let [m (mrows x!)\n          n (ncols x!)]\n      (dotimes [j n]\n        (let [col-j (col x! j)\n              [min-x max-x] (loop [i 1\n                                   min-val (entry col-j 0)\n                                   max-val (entry col-j 0)]\n                             (if (< i m)\n                               (let [val (entry col-j i)]\n                                 (recur (inc i)\n                                        (min min-val val)\n                                        (max max-val val)))\n                               [min-val max-val]))\n              range (- max-x min-x)]\n          (when-not (zero? range)\n            (linear-frac! (/ 1.0 range) col-j (/ (- min-x) range)))))\n      x!)))\n```\n:::\n\n\n\n### Feature Scaling\n\nFor algorithms sensitive to the sign of inputs or requiring symmetric ranges, scaling to [-1,1] is often more appropriate. The transformation extends min-max scaling:\n\n$$x_{normalized} = 2 \\cdot \\frac{x - min(x)}{max(x) - min(x)} - 1$$\n\nThis centers the data around zero while maintaining relative distances between points.\nFor matrices, each column is scaled independently to preserve feature-specific ranges.\n\n\n::: {.sourceClojure}\n```clojure\n(defn feature-scale!\n  \"Normalizes vectors or matrices to the range [-1, 1] in-place.\n   For matrices, normalizes each column independently.\n   Modifies the input in place.\n   Returns the modified input.\n   Returns columns unchanged if max equals min.\"\n  [x!]\n  (if (vector? x!)\n    ; Vector case\n    (let [n (dim x!)\n          [min-x max-x] (loop [i 1\n                               min-val (entry x! 0)\n                               max-val (entry x! 0)]\n                         (if (< i n)\n                           (let [val (entry x! i)]\n                             (recur (inc i)\n                                    (min min-val val)\n                                    (max max-val val)))\n                           [min-val max-val]))\n          range (- max-x min-x)]\n      (if (zero? range)\n        x!  ; Return unchanged if all values are the same\n        (linear-frac! (/ 2.0 range) x! (- (/ (+ min-x max-x) range)))))\n    ; Matrix case - normalize each column\n    (let [m (mrows x!)\n          n (ncols x!)]\n      (dotimes [j n]\n        (let [col-j (col x! j)\n              [min-x max-x] (loop [i 1\n                                   min-val (entry col-j 0)\n                                   max-val (entry col-j 0)]\n                             (if (< i m)\n                               (let [val (entry col-j i)]\n                                 (recur (inc i)\n                                        (min min-val val)\n                                        (max max-val val)))\n                               [min-val max-val]))\n              range (- max-x min-x)]\n          (when-not (zero? range)\n            (linear-frac! (/ 2.0 range) col-j (- (/ (+ min-x max-x) range))))))\n      x!)))\n```\n:::\n\n\n\n## Conclusion\n\nDescriptive statistics provide the foundation for understanding and preparing data for advanced analysis. The implementations in this chapter demonstrate how to efficiently compute and transform data while adhering to numerical computing best practices.\n\nThese tools provide essential data preprocessing capabilities for statistical analysis and machine learning applications. While what we have implemented is not exhaustive, it provides a foundation for more complex statistical computations. Next steps would be to implement robust statistics and more advanced data transformations.\n\n\n### Robust Statistics\n\nWhile *mean* and *variance* are fundamental statistical measures, they can be sensitive to *outliers* and extreme values. *Robust statistics* provide alternative measures that are less affected by anomalous data points.\n\n\n#### Median and Quantiles\n\nThe *median* is the middle value when data is ordered. For an odd number of observations, it is the middle value; for an even number, it is the average of the two middle values. Unlike the mean, the median is not influenced by extreme values.\n\nMore generally, *quantiles* divide ordered data into equal-sized groups. The *p-th quantile* is the value below which a proportion $p$ of the observations fall. Common quantiles include:\n\n- *Quartiles* (dividing data into four parts)\n- *Deciles* (ten parts)\n- *Percentiles* (hundred parts)\n\n\n#### Robust Scale Estimates\n\nThe *Median Absolute Deviation* (MAD) is a robust measure of variability:\n\n$$MAD = median(|x_i - median(x)|)$$\n\nThe MAD is particularly useful when data contains outliers that would distort the standard deviation.\n\n\n## Implementation Notes\n\n\n### Performance Considerations\n\nFor large datasets, consider:\n\n1. Using *in-place operations* when input preservation isn't required\n2. *Batching operations* to minimize memory allocation\n3. Taking advantage of *parallel processing* capabilities where available\n\nThe implementation uses *BLAS* (Basic Linear Algebra Subprograms) operations where possible for optimal performance on numerical computations.\n\n\n```{=html}\n<div style=\"background-color:grey;height:2px;width:100%;\"></div>\n```\n\n\n\n```{=html}\n<div></div>\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"number-sections":false,"highlight-style":"atom-one","output-file":"neandersolve.descriptive.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.39","theme":"united","code-block-background":true},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html","revealjs"]}