{"title":"Eigenvalues and Eigenvectors","markdown":{"yaml":{"format":{"html":{"toc":true,"toc-depth":3,"theme":"united","number-sections":false,"output-file":"neandersolve.eigen.html"}},"code-block-background":true,"highlight-style":"atom-one"},"headingText":"Eigenvalues and Eigenvectors","containsRefs":false,"markdown":"\n<style></style><style>.printedClojure .sourceCode {\n  background-color: transparent;\n  border-style: none;\n}\n</style><style>.clay-limit-image-width .clay-image {max-width: 100%}\n.clay-side-by-side .sourceCode {margin: 0}\n.clay-side-by-side {margin: 1em 0}\n</style>\n<script src=\"neandersolve.eigen_files/md-default0.js\" type=\"text/javascript\"></script><script src=\"neandersolve.eigen_files/md-default1.js\" type=\"text/javascript\"></script>\n\n::: {.sourceClojure}\n```clojure\n(ns neandersolve.eigen\n     (:require\n      [uncomplicate.fluokitten.core :refer [fmap!]]\n      [uncomplicate.neanderthal\n       [core :refer [axpy! col copy dia entry entry! gd \n                     ge mm mrows mv nrm2 raw scal vctr \n                     view-ge view-tr]]\n       [native :refer [dge]]\n       [linalg :refer [ev! org qrf trf tri!]]\n       [math :refer [abs]]]))\n```\n:::\n\n\n\n\n*Linear transformations* fundamentally change vectors in both magnitude and direction. However, certain special vectors maintain their direction under transformation, being only scaled by a factor. These vectors reveal intrinsic properties of the transformation that are crucial for understanding its behavior.\n\n\n## The Eigenvalue Equation\n\nFor a square matrix $A$, if there exists a non-zero vector $\\mathbf{v}$ and scalar $\\lambda$ satisfying:\n\n$$A \\phi = \\lambda \\phi$$\n\nthen $\\phi$ is called an *eigenvector* and $\\lambda$ its corresponding *eigenvalue*. This equation tells us that when $A$ transforms $\\phi$, the result points in the same (or opposite) direction as $\\phi$, scaled by $\\lambda$.\n\n\n## Power Iteration Method\n\nThe *power iteration method* provides a simple way to find the *dominant eigenvalue* and its corresponding eigenvector. Starting with a random vector $\\mathbf{x}_0$, we repeatedly apply the transformation:\n\n$$\\mathbf{x}_{k+1} = \\frac{A\\mathbf{x}_k}{\\|A\\mathbf{x}_k\\|}$$\n\nThis process converges to the eigenvector corresponding to the largest (in magnitude) eigenvalue. The convergence rate depends on the ratio between the largest and second-largest eigenvalues.\n\n\n::: {.sourceClojure}\n```clojure\n(defn power-iteration-step\n  \"Performs a single step of the power iteration method.\n   Returns [new-lambda new-vector]\"\n  [A x]\n  (let [y (mv A x)\n        lambda (nrm2 y)\n        x-next (scal (/ 1.0 lambda) y)]\n    [lambda x-next]))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn power-iteration\n  \"Implements the power method for finding the dominant eigenvalue and eigenvector.\n   Returns [eigenvalue eigenvector] after convergence or max iterations.\"\n  ([A]\n   (power-iteration A 1e-10 100))\n  ([A tol max-iter]\n   (let [n (mrows A)\n         x0 (entry! (vctr A n) 1.0)]\n    ;;  (println \"Matrix dimensions:\" (mrows A) \"x\" (ncols A))\n    ;;  (println \"Initial vector size:\" (dim x0))\n    ;;  (println \"Initial vector:\" x0)\n     (loop [x x0\n            iter 0\n            lambda-prev 0.0]\n      ;;  (println \"\\nIteration:\" iter)\n       (let [[lambda x-next] (power-iteration-step A x)]\n         ;;  (println \"Current lambda:\" lambda)\n         ;;  (println \"Lambda diff:\" (abs (- lambda lambda-prev)))\n         (if (or (< (abs (- lambda lambda-prev)) tol)\n                 (>= iter max-iter))\n           [lambda x-next]\n           (recur x-next (inc iter) lambda)))))))\n```\n:::\n\n\nConsider a simple example matrix:\n\n\n::: {.sourceClojure}\n```clojure\n(def test-matrix (dge 3 3 [4 2 3\n                           2 5 1\n                           3 1 6]))\n```\n:::\n\n\nThe power iteration method finds its dominant eigenvalue and vector:\n\n\n::: {.sourceClojure}\n```clojure\n(power-iteration test-matrix)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[9.143895446103055 #RealBlockVector[double, n:3, stride:1]\n[   0.57    0.44    0.69 ]\n]\n\n```\n:::\n\n\n\n## QR Algorithm\n\nWhile power iteration finds the dominant eigenvalue, the *QR algorithm* can compute all eigenvalues simultaneously. The method is based on the *QR decomposition*, where a matrix $A$ is factored into $A = QR$ with $Q$ orthogonal and $R$ upper triangular.\n\nThe algorithm proceeds iteratively:\n\n1. Start with $A_0 = A$\n2. At step $k$, compute $A_k = Q_kR_k$\n3. Form $A_{k+1} = R_kQ_k$\n\nAs $k$ increases, $A_k$ converges to an upper triangular matrix with eigenvalues on the diagonal. The convergence rate depends on the separation between eigenvalues.\n\n\n::: {.sourceClojure}\n```clojure\n(defn qr-step\n  \"Performs a single step of QR iteration.\n   Returns the next matrix in the sequence.\"\n  [A]\n  (let [fact (qrf A)  ; Get QR factorization\n        ;;  _ (println \"QR factorization created\")\n        Q (org fact)   ; Get orthogonal matrix Q\n        ;;  _ (println \"Q matrix extracted\")\n        ;;  _ (println \"Q:\" Q)\n        ; The R matrix is stored in the :or field of the factorization\n        R (view-tr (:or fact) {:uplo :upper})   ; Get upper triangular matrix R directly from factorization\n        ;;  _ (println \"R matrix extracted\")\n        _ (println \"R:\" R)\n        result (mm R Q)]  ; Compute next iteration\n    result))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn qr-algorithm\n  \"Implements the QR algorithm for computing all eigenvalues.\n   Returns a vector of eigenvalues after convergence.\"\n  ([A]\n   (qr-algorithm A 1e-10 100))\n  ([A tol max-iter]\n   (let [A0 (copy A)]\n    ;;  (println \"\\nStarting QR algorithm\")\n    ;;  (println \"Initial matrix:\" A0)\n     (loop [Ak A0\n            k 0]\n      ;;  (println \"\\nIteration:\" k)\n       (let [Ak+1 (qr-step Ak)\n             diff (nrm2 (axpy! -1 (dia Ak+1) (dia Ak)))]\n         ;;  (println \"Current diagonal:\" (dia Ak))\n         ;;  (println \"Next diagonal:\" (dia Ak+1))\n         ;;  (println \"Difference:\" diff)\n         (if (or (< diff tol) (>= k max-iter))\n           (dia Ak+1)\n           (recur Ak+1 (inc k))))))))\n```\n:::\n\n\nLet's examine the convergence on our test matrix:\n\n\n::: {.sourceClojure}\n```clojure\n(qr-algorithm test-matrix)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n#RealBlockVector[double, n:3, stride:4]\n[   9.14    4.38    1.47 ]\n\n\n```\n:::\n\n\n\n## Inverse Iteration\n\nOnce we have eigenvalues, we can find their corresponding eigenvectors using *inverse iteration*. This method is based on the observation that if $\\lambda$ is an eigenvalue of $A$, then $(A - \\lambda I)$ is singular, and its *null space* contains the corresponding eigenvector.\n\nThe algorithm applies power iteration to $(A - \\lambda I)^{-1}$:\n\n1. Start with a random vector $\\mathbf{x}_0$\n2. Solve $(A - \\lambda I)\\mathbf{y}_{k+1} = \\mathbf{x}_k$\n3. Set $\\mathbf{x}_{k+1} = \\mathbf{y}_{k+1}/\\|\\mathbf{y}_{k+1}\\|$\n\nThis process converges to the eigenvector corresponding to the eigenvalue closest to $\\lambda$. The convergence is typically rapid when $\\lambda$ is close to an actual eigenvalue.\n\n\n::: {.sourceClojure}\n```clojure\n(defn inverse-iteration\n  \"Implements inverse iteration for finding eigenvector given eigenvalue.\n   Returns the corresponding eigenvector after convergence.\"\n  ([A lambda]\n   (inverse-iteration A lambda 1e-10 100))\n  ([A lambda tol max-iter]\n   (let [n (mrows A)\n        ;;  _ (println \"Matrix dimension:\" n)\n         I (dge n n)\n         _ (dotimes [i n] (entry! I i i 1.0))\n         ;;  _ (println \"Identity matrix:\" I)\n         scaled-I (scal (- lambda) I)\n         ;;  _ (println \"Scaled identity matrix (-λI):\" scaled-I)\n         ;;  _ (println \"Original matrix A:\" A)\n         A-lambda-I (axpy! 1.0 (copy A) scaled-I)  ; A - λI\n         ;;  _ (println \"A - λI:\" A-lambda-I)\n         x0 (entry! (vctr A n) 1.0)]\n     (loop [x x0\n            iter 0]\n      ;;  (println \"\\nIteration:\" iter)\n      ;;  (println \"Current x:\" x)\n       (let [y (copy x)\n             ;;  _ (println \"y before solve:\" y)\n             ; Create fresh LU factorization for each solve\n             LU (trf (copy A-lambda-I))\n             ;;  _ (println \"LU matrix:\" LU)\n             ; Solve using tri! on fresh LU factorization\n             y-next (mv (tri! LU) y)\n             y-norm (nrm2 y-next)\n             ;;  _ (println \"y after solve:\" y-next)\n             ;;  _ (println \"y norm:\" y-norm)\n             x-next (scal (/ 1.0 y-norm) y-next)]\n         ;;  (println \"Next x:\" x-next)\n         (if (or (< (nrm2 (axpy! -1 x-next x)) tol)\n                 (>= iter max-iter))\n           x-next\n           (recur x-next (inc iter))))))))\n```\n:::\n\n\nUsing our test matrix and an eigenvalue from QR algorithm:\n\n\n::: {.sourceClojure}\n```clojure\n(def lambda1 (entry (qr-algorithm test-matrix) 0))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def v1 (inverse-iteration test-matrix lambda1))\n```\n:::\n\n\nWe can verify this is indeed an eigenpair:\n\n\n::: {.sourceClojure}\n```clojure\n(let [Av (mv test-matrix v1)\n      lambdav (scal lambda1 v1)]\n  (nrm2 (axpy! -1 Av lambdav)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n6.670682632020425E-12\n\n```\n:::\n\n\nThe small residual *norm* confirms that $\\lambda \\phi - A \\phi \\approx 0$, validating our computed eigenpair.\n\n\n## Complete Eigendecomposition\n\nWhile the previous methods find individual eigenvalues and eigenvectors, many applications require the complete *eigendecomposition*. A matrix $A$ can be decomposed as:\n\n$$A = \\Phi \\Lambda \\Phi^{-1}$$\n\nwhere $\\Lambda$ is a diagonal matrix of eigenvalues and $\\Phi$ contains the corresponding eigenvectors as columns. For *symmetric matrices*, $\\Phi$ is orthogonal, making the decomposition particularly useful for numerical computations.\n\nThe implementation handles both symmetric and general matrices efficiently:\n\n- For symmetric matrices, we use specialized algorithms that preserve symmetry\n- For general matrices, we handle potential complex eigenvalues\n- In both cases, eigenvalues are sorted by magnitude for consistency\n\n\n::: {.sourceClojure}\n```clojure\n(defn eigendecomposition\n  \"Computes complete eigendecomposition of a matrix.\n   Returns [eigenvalues eigenvectors] as matrices with eigenvalues sorted in descending order.\"\n  [A]\n  (let [n (mrows A)\n        symmetric? (instance? uncomplicate.neanderthal.internal.cpp.structures.RealUploMatrix A)\n        ;; Create matrices based on matrix type\n        [eigenvals eigenvecs]\n        (if symmetric?\n          ;; For symmetric matrices - use matrix directly\n          (let [d (gd A n)  ;; Diagonal matrix for eigenvalues\n                evecs (ge A n n)]  ;; Matrix for eigenvectors\n            (ev! A (view-ge (dia d)) nil evecs)  ;; Use symmetric matrix directly\n            ;; Extract diagonal values directly to vector\n            [(fmap! identity (dia d)) evecs])\n          ;; For general matrices\n          (let [evals (raw (ge A n 2))\n                evecs (ge A n n)]\n            (ev! (copy A) evals nil evecs)\n            ;; Extract first column (real parts) directly\n            [(fmap! identity (col evals 0)) evecs]))\n        ;; Create result matrices for sorted values\n        sorted-vals (vctr A n)\n        sorted-vecs (ge A n n)\n        ;; Find indices sorted by absolute eigenvalue magnitude\n        perm (vec (sort-by #(- (abs (entry eigenvals %))) (range n)))]\n    ;; Copy values in sorted order using efficient operations\n    (dotimes [i n]\n      (let [src-idx (perm i)]\n        (entry! sorted-vals i (entry eigenvals src-idx))\n        ;; Use axpy! for efficient column copy\n        (axpy! 1.0 (col eigenvecs src-idx) (col sorted-vecs i))))\n    [sorted-vals sorted-vecs]))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(eigendecomposition test-matrix)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   9.14    4.38    1.47 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.57   -0.02    0.82         \n   →       0.44   -0.83   -0.33         \n   →       0.69    0.55   -0.47         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn eigendecomposition!\n  \"In-place version of eigendecomposition that modifies the input matrices.\n   Requires pre-allocated eigenvals and eigenvecs matrices of correct dimensions.\"\n  [A eigenvals eigenvecs]\n  (ev! (copy A) eigenvals nil eigenvecs))\n```\n:::\n\n\n\n## Verification and Testing\n\nTo ensure the correctness of our eigendecomposition, we verify that each computed pair $(\\lambda, \\phi)$ satisfies the eigenvalue equation $A \\phi = \\lambda \\phi$ within numerical tolerance.\n\nThe verification process checks:\n\n1. *Eigenvalue equation*: $\\|A \\phi - \\lambda \\phi\\| \\approx 0$\n2. *Vector normalization*: $\\|\\phi\\| = 1$\n3. For symmetric matrices, *orthogonality*: $\\phi_i^T \\phi_j = 0$ for $i \\neq j$\n\n\n::: {.sourceClojure}\n```clojure\n(defn is-eigenpair?\n  \"Verifies if (lambda, v) is an eigenpair of matrix A within tolerance.\"\n  ([A lambda v]\n   (is-eigenpair? A lambda v 1e-8))\n  ([A lambda v tol]\n   (let [Av (mv A v)\n         lambdav (scal lambda v)]\n     (< (nrm2 (axpy! -1 Av lambdav)) tol))))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require '[neandersolve.descriptive :refer\n           [center! standardize! min-max! feature-scale!]])\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn test-eigenpairs\n  \"Tests and prints the eigenpairs of a given matrix.\n   Standardizes the matrix before computing eigendecomposition.\"\n  [A]\n  (let [[eigenvals eigenvecs] (eigendecomposition A)\n        n (mrows A)]\n    (println \"\\nTesting eigenpairs:\")\n    (loop [i 0]\n      (when (< i n)\n        (let [lambda (entry eigenvals i)\n              v (col eigenvecs i)\n              Av (mv A v)\n              lambdav (scal lambda v)\n              diff (nrm2 (axpy! -1 Av lambdav))]\n          (println \"Eigenvalue\" i \":\" lambda)\n          (println \"Eigenvector\" i \":\" (seq v))\n          (println \"Difference |Av - λv|:\" diff)\n          (println \"Is eigenpair?\" (is-eigenpair? A lambda v))\n          (println)\n          (recur (inc i)))))\n    [eigenvals eigenvecs]))\n```\n:::\n\n\nWe can test our implementation with different matrix preprocessing:\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs test-matrix)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   9.14    4.38    1.47 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.57   -0.02    0.82         \n   →       0.44   -0.83   -0.33         \n   →       0.69    0.55   -0.47         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nOriginal matrix\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs (standardize! (copy test-matrix)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[2.1     1.1     2.46E-17]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.16    0.68    0.32         \n   →      -0.77    0.05    0.76         \n   →       0.62   -0.73    0.57         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nStandardized\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs (center! (copy test-matrix)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   4.53    1.47   -0.00 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.08   -0.81    0.60         \n   →      -0.74    0.34    0.68         \n   →       0.67    0.47    0.43         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nCentered\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs (min-max! (copy test-matrix)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   1.45    1.00    0.55 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →      -0.67    0.00   -0.67         \n   →       0.00    0.85    0.00         \n   →      -0.75   -0.53    0.75         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nMin-max scaled\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs (feature-scale! (copy test-matrix)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   2.15    1.13   -0.29 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.21   -0.70    0.37         \n   →      -0.74   -0.10    0.73         \n   →       0.64    0.71    0.57         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nFeature scaled\n\n\n## Matrix Powers and Similarity\n\nOne powerful application of eigendecomposition is efficient computation of matrix powers. For a diagonalizable matrix $A = \\Phi \\Lambda \\Phi^{-1}$, we have:\n\n$$A^k = (\\Phi \\Lambda \\Phi^{-1})^k = \\Phi \\Lambda^k \\Phi^{-1}$$\n\nThis allows us to compute high powers of matrices without repeated multiplication, which is particularly useful in:\n\n- *Markov chains*: Computing steady-state distributions\n- *Dynamical systems*: Analyzing long-term behavior\n- *Network analysis*: Computing multi-step connections\n\nThe implementation demonstrates this with a simple example:\n\n\n::: {.sourceClojure}\n```clojure\n(comment\n  (let [A (dge 2 2 [-4 3 -6 5])\n        evec (dge 2 2)\n        eval (ev! (copy A) (raw A) nil evec)\n        inv-evec (tri! (trf evec))\n        d (mm inv-evec (mm A evec))]\n    (fmap! (pow 9) (dia d))\n    d))\n```\n:::\n\n\n\n```{=html}\n<div style=\"background-color:grey;height:2px;width:100%;\"></div>\n```\n\n\n\n```{=html}\n<div></div>\n```\n","srcMarkdownNoYaml":"\n<style></style><style>.printedClojure .sourceCode {\n  background-color: transparent;\n  border-style: none;\n}\n</style><style>.clay-limit-image-width .clay-image {max-width: 100%}\n.clay-side-by-side .sourceCode {margin: 0}\n.clay-side-by-side {margin: 1em 0}\n</style>\n<script src=\"neandersolve.eigen_files/md-default0.js\" type=\"text/javascript\"></script><script src=\"neandersolve.eigen_files/md-default1.js\" type=\"text/javascript\"></script>\n\n::: {.sourceClojure}\n```clojure\n(ns neandersolve.eigen\n     (:require\n      [uncomplicate.fluokitten.core :refer [fmap!]]\n      [uncomplicate.neanderthal\n       [core :refer [axpy! col copy dia entry entry! gd \n                     ge mm mrows mv nrm2 raw scal vctr \n                     view-ge view-tr]]\n       [native :refer [dge]]\n       [linalg :refer [ev! org qrf trf tri!]]\n       [math :refer [abs]]]))\n```\n:::\n\n\n\n# Eigenvalues and Eigenvectors\n\n*Linear transformations* fundamentally change vectors in both magnitude and direction. However, certain special vectors maintain their direction under transformation, being only scaled by a factor. These vectors reveal intrinsic properties of the transformation that are crucial for understanding its behavior.\n\n\n## The Eigenvalue Equation\n\nFor a square matrix $A$, if there exists a non-zero vector $\\mathbf{v}$ and scalar $\\lambda$ satisfying:\n\n$$A \\phi = \\lambda \\phi$$\n\nthen $\\phi$ is called an *eigenvector* and $\\lambda$ its corresponding *eigenvalue*. This equation tells us that when $A$ transforms $\\phi$, the result points in the same (or opposite) direction as $\\phi$, scaled by $\\lambda$.\n\n\n## Power Iteration Method\n\nThe *power iteration method* provides a simple way to find the *dominant eigenvalue* and its corresponding eigenvector. Starting with a random vector $\\mathbf{x}_0$, we repeatedly apply the transformation:\n\n$$\\mathbf{x}_{k+1} = \\frac{A\\mathbf{x}_k}{\\|A\\mathbf{x}_k\\|}$$\n\nThis process converges to the eigenvector corresponding to the largest (in magnitude) eigenvalue. The convergence rate depends on the ratio between the largest and second-largest eigenvalues.\n\n\n::: {.sourceClojure}\n```clojure\n(defn power-iteration-step\n  \"Performs a single step of the power iteration method.\n   Returns [new-lambda new-vector]\"\n  [A x]\n  (let [y (mv A x)\n        lambda (nrm2 y)\n        x-next (scal (/ 1.0 lambda) y)]\n    [lambda x-next]))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn power-iteration\n  \"Implements the power method for finding the dominant eigenvalue and eigenvector.\n   Returns [eigenvalue eigenvector] after convergence or max iterations.\"\n  ([A]\n   (power-iteration A 1e-10 100))\n  ([A tol max-iter]\n   (let [n (mrows A)\n         x0 (entry! (vctr A n) 1.0)]\n    ;;  (println \"Matrix dimensions:\" (mrows A) \"x\" (ncols A))\n    ;;  (println \"Initial vector size:\" (dim x0))\n    ;;  (println \"Initial vector:\" x0)\n     (loop [x x0\n            iter 0\n            lambda-prev 0.0]\n      ;;  (println \"\\nIteration:\" iter)\n       (let [[lambda x-next] (power-iteration-step A x)]\n         ;;  (println \"Current lambda:\" lambda)\n         ;;  (println \"Lambda diff:\" (abs (- lambda lambda-prev)))\n         (if (or (< (abs (- lambda lambda-prev)) tol)\n                 (>= iter max-iter))\n           [lambda x-next]\n           (recur x-next (inc iter) lambda)))))))\n```\n:::\n\n\nConsider a simple example matrix:\n\n\n::: {.sourceClojure}\n```clojure\n(def test-matrix (dge 3 3 [4 2 3\n                           2 5 1\n                           3 1 6]))\n```\n:::\n\n\nThe power iteration method finds its dominant eigenvalue and vector:\n\n\n::: {.sourceClojure}\n```clojure\n(power-iteration test-matrix)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[9.143895446103055 #RealBlockVector[double, n:3, stride:1]\n[   0.57    0.44    0.69 ]\n]\n\n```\n:::\n\n\n\n## QR Algorithm\n\nWhile power iteration finds the dominant eigenvalue, the *QR algorithm* can compute all eigenvalues simultaneously. The method is based on the *QR decomposition*, where a matrix $A$ is factored into $A = QR$ with $Q$ orthogonal and $R$ upper triangular.\n\nThe algorithm proceeds iteratively:\n\n1. Start with $A_0 = A$\n2. At step $k$, compute $A_k = Q_kR_k$\n3. Form $A_{k+1} = R_kQ_k$\n\nAs $k$ increases, $A_k$ converges to an upper triangular matrix with eigenvalues on the diagonal. The convergence rate depends on the separation between eigenvalues.\n\n\n::: {.sourceClojure}\n```clojure\n(defn qr-step\n  \"Performs a single step of QR iteration.\n   Returns the next matrix in the sequence.\"\n  [A]\n  (let [fact (qrf A)  ; Get QR factorization\n        ;;  _ (println \"QR factorization created\")\n        Q (org fact)   ; Get orthogonal matrix Q\n        ;;  _ (println \"Q matrix extracted\")\n        ;;  _ (println \"Q:\" Q)\n        ; The R matrix is stored in the :or field of the factorization\n        R (view-tr (:or fact) {:uplo :upper})   ; Get upper triangular matrix R directly from factorization\n        ;;  _ (println \"R matrix extracted\")\n        _ (println \"R:\" R)\n        result (mm R Q)]  ; Compute next iteration\n    result))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn qr-algorithm\n  \"Implements the QR algorithm for computing all eigenvalues.\n   Returns a vector of eigenvalues after convergence.\"\n  ([A]\n   (qr-algorithm A 1e-10 100))\n  ([A tol max-iter]\n   (let [A0 (copy A)]\n    ;;  (println \"\\nStarting QR algorithm\")\n    ;;  (println \"Initial matrix:\" A0)\n     (loop [Ak A0\n            k 0]\n      ;;  (println \"\\nIteration:\" k)\n       (let [Ak+1 (qr-step Ak)\n             diff (nrm2 (axpy! -1 (dia Ak+1) (dia Ak)))]\n         ;;  (println \"Current diagonal:\" (dia Ak))\n         ;;  (println \"Next diagonal:\" (dia Ak+1))\n         ;;  (println \"Difference:\" diff)\n         (if (or (< diff tol) (>= k max-iter))\n           (dia Ak+1)\n           (recur Ak+1 (inc k))))))))\n```\n:::\n\n\nLet's examine the convergence on our test matrix:\n\n\n::: {.sourceClojure}\n```clojure\n(qr-algorithm test-matrix)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n#RealBlockVector[double, n:3, stride:4]\n[   9.14    4.38    1.47 ]\n\n\n```\n:::\n\n\n\n## Inverse Iteration\n\nOnce we have eigenvalues, we can find their corresponding eigenvectors using *inverse iteration*. This method is based on the observation that if $\\lambda$ is an eigenvalue of $A$, then $(A - \\lambda I)$ is singular, and its *null space* contains the corresponding eigenvector.\n\nThe algorithm applies power iteration to $(A - \\lambda I)^{-1}$:\n\n1. Start with a random vector $\\mathbf{x}_0$\n2. Solve $(A - \\lambda I)\\mathbf{y}_{k+1} = \\mathbf{x}_k$\n3. Set $\\mathbf{x}_{k+1} = \\mathbf{y}_{k+1}/\\|\\mathbf{y}_{k+1}\\|$\n\nThis process converges to the eigenvector corresponding to the eigenvalue closest to $\\lambda$. The convergence is typically rapid when $\\lambda$ is close to an actual eigenvalue.\n\n\n::: {.sourceClojure}\n```clojure\n(defn inverse-iteration\n  \"Implements inverse iteration for finding eigenvector given eigenvalue.\n   Returns the corresponding eigenvector after convergence.\"\n  ([A lambda]\n   (inverse-iteration A lambda 1e-10 100))\n  ([A lambda tol max-iter]\n   (let [n (mrows A)\n        ;;  _ (println \"Matrix dimension:\" n)\n         I (dge n n)\n         _ (dotimes [i n] (entry! I i i 1.0))\n         ;;  _ (println \"Identity matrix:\" I)\n         scaled-I (scal (- lambda) I)\n         ;;  _ (println \"Scaled identity matrix (-λI):\" scaled-I)\n         ;;  _ (println \"Original matrix A:\" A)\n         A-lambda-I (axpy! 1.0 (copy A) scaled-I)  ; A - λI\n         ;;  _ (println \"A - λI:\" A-lambda-I)\n         x0 (entry! (vctr A n) 1.0)]\n     (loop [x x0\n            iter 0]\n      ;;  (println \"\\nIteration:\" iter)\n      ;;  (println \"Current x:\" x)\n       (let [y (copy x)\n             ;;  _ (println \"y before solve:\" y)\n             ; Create fresh LU factorization for each solve\n             LU (trf (copy A-lambda-I))\n             ;;  _ (println \"LU matrix:\" LU)\n             ; Solve using tri! on fresh LU factorization\n             y-next (mv (tri! LU) y)\n             y-norm (nrm2 y-next)\n             ;;  _ (println \"y after solve:\" y-next)\n             ;;  _ (println \"y norm:\" y-norm)\n             x-next (scal (/ 1.0 y-norm) y-next)]\n         ;;  (println \"Next x:\" x-next)\n         (if (or (< (nrm2 (axpy! -1 x-next x)) tol)\n                 (>= iter max-iter))\n           x-next\n           (recur x-next (inc iter))))))))\n```\n:::\n\n\nUsing our test matrix and an eigenvalue from QR algorithm:\n\n\n::: {.sourceClojure}\n```clojure\n(def lambda1 (entry (qr-algorithm test-matrix) 0))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(def v1 (inverse-iteration test-matrix lambda1))\n```\n:::\n\n\nWe can verify this is indeed an eigenpair:\n\n\n::: {.sourceClojure}\n```clojure\n(let [Av (mv test-matrix v1)\n      lambdav (scal lambda1 v1)]\n  (nrm2 (axpy! -1 Av lambdav)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n6.670682632020425E-12\n\n```\n:::\n\n\nThe small residual *norm* confirms that $\\lambda \\phi - A \\phi \\approx 0$, validating our computed eigenpair.\n\n\n## Complete Eigendecomposition\n\nWhile the previous methods find individual eigenvalues and eigenvectors, many applications require the complete *eigendecomposition*. A matrix $A$ can be decomposed as:\n\n$$A = \\Phi \\Lambda \\Phi^{-1}$$\n\nwhere $\\Lambda$ is a diagonal matrix of eigenvalues and $\\Phi$ contains the corresponding eigenvectors as columns. For *symmetric matrices*, $\\Phi$ is orthogonal, making the decomposition particularly useful for numerical computations.\n\nThe implementation handles both symmetric and general matrices efficiently:\n\n- For symmetric matrices, we use specialized algorithms that preserve symmetry\n- For general matrices, we handle potential complex eigenvalues\n- In both cases, eigenvalues are sorted by magnitude for consistency\n\n\n::: {.sourceClojure}\n```clojure\n(defn eigendecomposition\n  \"Computes complete eigendecomposition of a matrix.\n   Returns [eigenvalues eigenvectors] as matrices with eigenvalues sorted in descending order.\"\n  [A]\n  (let [n (mrows A)\n        symmetric? (instance? uncomplicate.neanderthal.internal.cpp.structures.RealUploMatrix A)\n        ;; Create matrices based on matrix type\n        [eigenvals eigenvecs]\n        (if symmetric?\n          ;; For symmetric matrices - use matrix directly\n          (let [d (gd A n)  ;; Diagonal matrix for eigenvalues\n                evecs (ge A n n)]  ;; Matrix for eigenvectors\n            (ev! A (view-ge (dia d)) nil evecs)  ;; Use symmetric matrix directly\n            ;; Extract diagonal values directly to vector\n            [(fmap! identity (dia d)) evecs])\n          ;; For general matrices\n          (let [evals (raw (ge A n 2))\n                evecs (ge A n n)]\n            (ev! (copy A) evals nil evecs)\n            ;; Extract first column (real parts) directly\n            [(fmap! identity (col evals 0)) evecs]))\n        ;; Create result matrices for sorted values\n        sorted-vals (vctr A n)\n        sorted-vecs (ge A n n)\n        ;; Find indices sorted by absolute eigenvalue magnitude\n        perm (vec (sort-by #(- (abs (entry eigenvals %))) (range n)))]\n    ;; Copy values in sorted order using efficient operations\n    (dotimes [i n]\n      (let [src-idx (perm i)]\n        (entry! sorted-vals i (entry eigenvals src-idx))\n        ;; Use axpy! for efficient column copy\n        (axpy! 1.0 (col eigenvecs src-idx) (col sorted-vecs i))))\n    [sorted-vals sorted-vecs]))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(eigendecomposition test-matrix)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   9.14    4.38    1.47 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.57   -0.02    0.82         \n   →       0.44   -0.83   -0.33         \n   →       0.69    0.55   -0.47         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn eigendecomposition!\n  \"In-place version of eigendecomposition that modifies the input matrices.\n   Requires pre-allocated eigenvals and eigenvecs matrices of correct dimensions.\"\n  [A eigenvals eigenvecs]\n  (ev! (copy A) eigenvals nil eigenvecs))\n```\n:::\n\n\n\n## Verification and Testing\n\nTo ensure the correctness of our eigendecomposition, we verify that each computed pair $(\\lambda, \\phi)$ satisfies the eigenvalue equation $A \\phi = \\lambda \\phi$ within numerical tolerance.\n\nThe verification process checks:\n\n1. *Eigenvalue equation*: $\\|A \\phi - \\lambda \\phi\\| \\approx 0$\n2. *Vector normalization*: $\\|\\phi\\| = 1$\n3. For symmetric matrices, *orthogonality*: $\\phi_i^T \\phi_j = 0$ for $i \\neq j$\n\n\n::: {.sourceClojure}\n```clojure\n(defn is-eigenpair?\n  \"Verifies if (lambda, v) is an eigenpair of matrix A within tolerance.\"\n  ([A lambda v]\n   (is-eigenpair? A lambda v 1e-8))\n  ([A lambda v tol]\n   (let [Av (mv A v)\n         lambdav (scal lambda v)]\n     (< (nrm2 (axpy! -1 Av lambdav)) tol))))\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(require '[neandersolve.descriptive :refer\n           [center! standardize! min-max! feature-scale!]])\n```\n:::\n\n\n\n::: {.sourceClojure}\n```clojure\n(defn test-eigenpairs\n  \"Tests and prints the eigenpairs of a given matrix.\n   Standardizes the matrix before computing eigendecomposition.\"\n  [A]\n  (let [[eigenvals eigenvecs] (eigendecomposition A)\n        n (mrows A)]\n    (println \"\\nTesting eigenpairs:\")\n    (loop [i 0]\n      (when (< i n)\n        (let [lambda (entry eigenvals i)\n              v (col eigenvecs i)\n              Av (mv A v)\n              lambdav (scal lambda v)\n              diff (nrm2 (axpy! -1 Av lambdav))]\n          (println \"Eigenvalue\" i \":\" lambda)\n          (println \"Eigenvector\" i \":\" (seq v))\n          (println \"Difference |Av - λv|:\" diff)\n          (println \"Is eigenpair?\" (is-eigenpair? A lambda v))\n          (println)\n          (recur (inc i)))))\n    [eigenvals eigenvecs]))\n```\n:::\n\n\nWe can test our implementation with different matrix preprocessing:\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs test-matrix)\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   9.14    4.38    1.47 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.57   -0.02    0.82         \n   →       0.44   -0.83   -0.33         \n   →       0.69    0.55   -0.47         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nOriginal matrix\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs (standardize! (copy test-matrix)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[2.1     1.1     2.46E-17]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.16    0.68    0.32         \n   →      -0.77    0.05    0.76         \n   →       0.62   -0.73    0.57         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nStandardized\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs (center! (copy test-matrix)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   4.53    1.47   -0.00 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.08   -0.81    0.60         \n   →      -0.74    0.34    0.68         \n   →       0.67    0.47    0.43         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nCentered\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs (min-max! (copy test-matrix)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   1.45    1.00    0.55 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →      -0.67    0.00   -0.67         \n   →       0.00    0.85    0.00         \n   →      -0.75   -0.53    0.75         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nMin-max scaled\n\n\n::: {.sourceClojure}\n```clojure\n(test-eigenpairs (feature-scale! (copy test-matrix)))\n```\n:::\n\n\n\n::: {.printedClojure}\n```clojure\n[#RealBlockVector[double, n:3, stride:1]\n[   2.15    1.13   -0.29 ]\n #RealGEMatrix[double, mxn:3x3, layout:column]\n   ▥       ↓       ↓       ↓       ┓    \n   →       0.21   -0.70    0.37         \n   →      -0.74   -0.10    0.73         \n   →       0.64    0.71    0.57         \n   ┗                               ┛    \n]\n\n```\n:::\n\n\nFeature scaled\n\n\n## Matrix Powers and Similarity\n\nOne powerful application of eigendecomposition is efficient computation of matrix powers. For a diagonalizable matrix $A = \\Phi \\Lambda \\Phi^{-1}$, we have:\n\n$$A^k = (\\Phi \\Lambda \\Phi^{-1})^k = \\Phi \\Lambda^k \\Phi^{-1}$$\n\nThis allows us to compute high powers of matrices without repeated multiplication, which is particularly useful in:\n\n- *Markov chains*: Computing steady-state distributions\n- *Dynamical systems*: Analyzing long-term behavior\n- *Network analysis*: Computing multi-step connections\n\nThe implementation demonstrates this with a simple example:\n\n\n::: {.sourceClojure}\n```clojure\n(comment\n  (let [A (dge 2 2 [-4 3 -6 5])\n        evec (dge 2 2)\n        eval (ev! (copy A) (raw A) nil evec)\n        inv-evec (tri! (trf evec))\n        d (mm inv-evec (mm A evec))]\n    (fmap! (pow 9) (dia d))\n    d))\n```\n:::\n\n\n\n```{=html}\n<div style=\"background-color:grey;height:2px;width:100%;\"></div>\n```\n\n\n\n```{=html}\n<div></div>\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"number-sections":false,"highlight-style":"atom-one","output-file":"neandersolve.eigen.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.39","theme":"united","code-block-background":true},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html","revealjs"]}